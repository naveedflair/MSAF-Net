# -*- coding: utf-8 -*-
"""Untitled4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rDV1EceVBQpoacWnWM3LKJkYH9Rq5Qwz
"""

import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import cv2
from sklearn.metrics import roc_curve, auc, precision_recall_curve
from ..training.metrics import dice_coefficient, iou_score

def plot_training_curves(train_losses, val_losses, train_ious, val_ious, train_dices, val_dices):
    plt.figure(figsize=(18, 6))

    plt.subplot(1, 3, 1)
    plt.plot(train_losses, label='Train Loss')
    plt.plot(val_losses, label='Validation Loss')
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.title('Training and Validation Loss')
    plt.legend()

    plt.subplot(1, 3, 2)
    plt.plot(train_ious, label='Train IoU')
    plt.plot(val_ious, label='Validation IoU')
    plt.xlabel('Epoch')
    plt.ylabel('IoU')
    plt.title('Training and Validation IoU')
    plt.legend()

    plt.subplot(1, 3, 3)
    plt.plot(train_dices, label='Train Dice')
    plt.plot(val_dices, label='Validation Dice')
    plt.xlabel('Epoch')
    plt.ylabel('Dice Coefficient')
    plt.title('Training and Validation Dice Coefficient')
    plt.legend()

    plt.tight_layout()
    plt.savefig('training_curves_CHAOS.png')
    plt.show()

def save_and_plot_predictions_fixed(model, images, masks, device, num_images=10):
    model.eval()
    preds_list = []

    with torch.no_grad():
        images_tensor = torch.tensor(images).to(device)
        masks_tensor = torch.tensor(masks).to(device)

        outputs = model(images_tensor)
        preds_list = (outputs > 0.5).float().cpu().numpy()

    fig, axs = plt.subplots(num_images, 3, figsize=(12, num_images * 4))
    for i in range(num_images):
        image = np.squeeze(images[i])
        mask = np.squeeze(masks[i])
        pred = np.squeeze(preds_list[i])

        mask = (mask * 255).astype(np.uint8)
        contours_gt, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        pred = (pred * 255).astype(np.uint8)
        contours_pred, _ = cv2.findContours(pred, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        pred_with_boundaries = cv2.cvtColor(pred, cv2.COLOR_GRAY2BGR)
        cv2.drawContours(pred_with_boundaries, contours_gt, -1, (255, 0, 0), 1)
        cv2.drawContours(pred_with_boundaries, contours_pred, -1, (0, 255, 0), 1)

        axs[i, 0].imshow(image, cmap='gray')
        axs[i, 0].set_title('Input Image')
        axs[i, 0].axis('off')

        axs[i, 1].imshow(mask, cmap='gray')
        axs[i, 1].set_title('Ground Truth Mask')
        axs[i, 1].axis('off')

        axs[i, 2].imshow(pred_with_boundaries)
        axs[i, 2].set_title('Prediction with Boundaries')
        axs[i, 2].axis('off')

    plt.tight_layout()
    plt.savefig('segmentation_predictions_fixed.png')
    plt.show()

# Save and plot predictions
save_and_plot_predictions_fixed(model, fixed_test_images, fixed_test_masks, num_images=10)

# Plot attention maps on fixed images
def plot_attention_maps_fixed(model, images, device, num_samples=5):
    model.eval()
    fig, axes = plt.subplots(num_samples, 5, figsize=(20, 4 * num_samples))

    with torch.no_grad():
        images_tensor = torch.tensor(images[:num_samples]).to(device)

        for idx in range(num_samples):
            x = model.backbone.conv1(images_tensor[idx].unsqueeze(0))
            x = model.backbone.bn1(x)
            x = model.backbone.relu(x)
            x = model.backbone.maxpool(x)

            features = model.fpn(x)
            attention_maps = [attention(feature) for attention, feature in zip(model.attention, features)]

            axes[idx, 0].imshow(images_tensor[idx, 0].cpu(), cmap='gray')
            axes[idx, 0].set_title('Original Image')
            axes[idx, 0].axis('off')

            for level, att_map in enumerate(attention_maps, 1):
                att = torch.nn.functional.interpolate(att_map, size=images_tensor[idx].shape[1:], mode='bilinear', align_corners=False)
                att = att[0, 0].cpu()
                axes[idx, level].imshow(att, cmap='hot')
                axes[idx, level].set_title(f'Attention Level {level}')
                axes[idx, level].axis('off')

    plt.tight_layout()
    plt.savefig('attention_maps_fixed.png')
    plt.show()

def calculate_metrics(model, loader, device):
    """Calculate ROC and PR curve data."""
    model.eval()
    all_preds = []
    all_targets = []

    with torch.no_grad():
        for images, masks in loader:
            images, masks = images.to(device), masks.to(device)
            outputs = model(images)

            all_preds.extend(outputs.cpu().numpy().flatten())
            all_targets.extend(masks.cpu().numpy().flatten())

    return np.array(all_preds), np.array(all_targets)

def plot_roc_pr_curves(predictions, targets):
    """Plot ROC and PR curves."""
    # Calculate ROC curve
    fpr, tpr, _ = roc_curve(targets, predictions)
    roc_auc = auc(fpr, tpr)

    # Calculate PR curve
    precision, recall, _ = precision_recall_curve(targets, predictions)
    pr_auc = auc(recall, precision)

    # Plot both curves
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))

    # ROC curve
    ax1.plot(fpr, tpr, color='darkorange', lw=2, label=f'ROC curve (AUC = {roc_auc:.2f})')
    ax1.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')
    ax1.set_xlim([0.0, 1.0])
    ax1.set_ylim([0.0, 1.05])
    ax1.set_xlabel('False Positive Rate')
    ax1.set_ylabel('True Positive Rate')
    ax1.set_title('Receiver Operating Characteristic (ROC) Curve')
    ax1.legend(loc="lower right")

    # PR curve
    ax2.plot(recall, precision, color='blue', lw=2, label=f'PR curve (AUC = {pr_auc:.2f})')
    ax2.set_xlim([0.0, 1.0])
    ax2.set_ylim([0.0, 1.05])
    ax2.set_xlabel('Recall')
    ax2.set_ylabel('Precision')
    ax2.set_title('Precision-Recall Curve')
    ax2.legend(loc="lower left")

    plt.tight_layout()
    plt.savefig('roc_pr_curves.png')
    plt.show()

def plot_confusion_matrix(predictions, targets, threshold=0.5):
    """Plot pixel-wise confusion matrix."""
    pred_binary = (predictions > threshold).astype(int)

    # Calculate confusion matrix values
    tn = np.sum((pred_binary == 0) & (targets == 0))
    fp = np.sum((pred_binary == 1) & (targets == 0))
    fn = np.sum((pred_binary == 0) & (targets == 1))
    tp = np.sum((pred_binary == 1) & (targets == 1))

    cm = np.array([[tn, fp], [fn, tp]])

    # Plot confusion matrix
    plt.figure(figsize=(8, 6))
    sns.heatmap(cm, annot=True, fmt='g', cmap='Blues',
                xticklabels=['Negative', 'Positive'],
                yticklabels=['Negative', 'Positive'])
    plt.title('Pixel-wise Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.savefig('confusion_matrix.png')
    plt.show()

def plot_metrics_distribution(predictions, targets, threshold=0.5):
    """Plot distribution of various metrics across samples."""
    pred_binary = (predictions > threshold).astype(int)

    # Calculate per-image metrics
    n_samples = len(pred_binary)
    dice_scores = []
    iou_scores = []

    for i in range(n_samples):
        dice = dice_coefficient(torch.tensor(pred_binary[i]), torch.tensor(targets[i]))
        iou = iou_score(torch.tensor(pred_binary[i]), torch.tensor(targets[i]))
        dice_scores.append(dice)
        iou_scores.append(iou)

    # Plot distributions
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))

    ax1.hist(dice_scores, bins=20, color='blue', alpha=0.7)
    ax1.set_title('Distribution of Dice Scores')
    ax1.set_xlabel('Dice Score')
    ax1.set_ylabel('Frequency')

    ax2.hist(iou_scores, bins=20, color='green', alpha=0.7)
    ax2.set_title('Distribution of IoU Scores')
    ax2.set_xlabel('IoU Score')
    ax2.set_ylabel('Frequency')

    plt.tight_layout()
    plt.savefig('metrics_distribution.png')
    plt.show()


# Visualize FPN features on fixed images
def visualize_fpn_features_fixed(model, images, device):
    model.eval()
    images_tensor = torch.tensor(images).to(device)

    with torch.no_grad():
        x = model.backbone.conv1(images_tensor)
        x = model.backbone.bn1(x)
        x = model.backbone.relu(x)
        x = model.backbone.maxpool(x)
        fpn_features = model.fpn(x)

    batch_size = images_tensor.size(0)
    fig, axes = plt.subplots(batch_size, len(fpn_features) + 1, figsize=(20, 4 * batch_size))

    if batch_size == 1:
        axes = axes.reshape(1, -1)

    for i in range(batch_size):
        axes[i, 0].imshow(images_tensor[i, 0].cpu(), cmap='gray')
        axes[i, 0].set_title(f'Original Image {i+1}')
        axes[i, 0].axis('off')

        for j, feature_map in enumerate(fpn_features):
            feature = feature_map[i].mean(dim=0).cpu()
            feature = (feature - feature.min()) / (feature.max() - feature.min() + 1e-8)
            axes[i, j + 1].imshow(feature, cmap='hot')
            axes[i, j + 1].set_title(f'FPN Level {j+1}')
            axes[i, j + 1].axis('off')

    plt.suptitle('FPN Multi-scale Feature Maps', fontsize=16)
    plt.tight_layout()
    plt.savefig('fpn_features_fixed.png' , dpi=300, bbox_inches='tight')
    plt.show()


# Add description of feature levels
def print_fpn_description():
    print("\nFPN Feature Levels Description:")
    print("Level 1 (P1): Finest scale, good for small object details")
    print("Level 2 (P2): Medium-fine scale, balancing detail and context")
    print("Level 3 (P3): Medium-coarse scale, more contextual information")
    print("Level 4 (P4): Coarsest scale, captures global context")
    print("\nColor intensity in feature maps indicates activation strength:")
    print("- Brighter colors (yellow/white) indicate stronger activations")
    print("- Darker colors (red/black) indicate weaker activations\n")

# Use these functions after training
print("\nVisualizing FPN multi-scale features...")

print_fpn_description()


# Add this code block after your training loop and before final evaluation
print("Generating visualization plots...")


    # Plot predictions
#save_and_plot_predictions_fixed(model, fixed_test_images, fixed_test_masks, num_images=10)

# Plot FPN feature maps
visualize_fpn_features_fixed(model, fixed_test_images, device)

    # Plot attention maps
plot_attention_maps_fixed(model, fixed_test_images, device, num_samples=10)

# Calculate predictions and targets for the entire test set
predictions, targets = calculate_metrics(model, test_loader, device)

# Plot ROC and PR curves
plot_roc_pr_curves(predictions, targets)

# Plot confusion matrix
plot_confusion_matrix(predictions, targets)

# Plot metrics distribution
plot_metrics_distribution(predictions, targets)

print("Visualization plots have been saved!")